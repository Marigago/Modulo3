{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuraciones comunes para un ambiente de `MLflow Tracking`.\n",
    "![](https://mlflow.org/docs/3.0.1/assets/images/tracking-setup-overview-3d8cfd511355d9379328d69573763331.png)\n",
    "\n",
    "### Escenario 2\n",
    "```python\n",
    "# set mlflow tracking uri\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri('sqlite:///mlflow.db')\n",
    "```\n",
    "\n",
    "### Escenario 3\n",
    "MLFlow remoto\n",
    "\n",
    "```python\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri('url/remote/server')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Escenario | 1. Localhost (por defecto) | 2. Seguimiento local con base de datos local | 3. Seguimiento remoto con **MLflow Tracking Server** |\n",
    "|------------|-----------------------------|-----------------------------------------------|------------------------------------------------------|\n",
    "| **Caso de uso** | Desarrollo individual | Desarrollo individual | Desarrollo en equipo |\n",
    "| **Descripci√≥n** | Por defecto, MLflow guarda los metadatos y artefactos de cada ejecuci√≥n en un directorio local llamado `mlruns`. Es la forma m√°s simple de comenzar con MLflow Tracking, sin necesidad de configurar servidores, bases de datos o almacenamiento externos. | El cliente de MLflow puede conectarse con una base de datos compatible con SQLAlchemy (por ejemplo, SQLite, PostgreSQL o MySQL) como *backend*. Guardar los metadatos en una base de datos permite una gesti√≥n m√°s limpia de los datos de los experimentos, evitando el esfuerzo de configurar un servidor. | El servidor de seguimiento de MLflow puede configurarse con un *proxy* HTTP para artefactos, redirigiendo las solicitudes de artefactos a trav√©s del servidor para almacenar y recuperar sin interactuar directamente con los servicios de almacenamiento subyacentes. Es especialmente √∫til para entornos de trabajo en equipo, donde se necesita almacenar artefactos y metadatos de experimentos en una ubicaci√≥n compartida con control de acceso adecuado. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `MLflow`: Beneficios\n",
    "* El `Tracking server` puede ser f√°cilmente desplegado en la nube\n",
    "* Compartir experimentos con otros Data Scientists\n",
    "* Colaborar con otros para construir y desplegar modelos\n",
    "* Dar m√°s visibilidad de los esfuerzos del equipo de Data Science.\n",
    "\n",
    "## `MLflow`: Problemas cuando se ejecutan servidores remotos compartidos\n",
    "* Seguridad:\n",
    "    * Restringir el acceso al server (por ejemplo a trav√©s de una VPN)\n",
    "* Isolation:\n",
    "    * Definir un est√°ndar para nombrar experimentos, modelos y un conjunto de tags predeterminados.\n",
    "    * Restringir el acceso a los artefactos  \n",
    "\n",
    "## `MLflow`: Limitaciones\n",
    "* **Autenticaci√≥n y Usuarios:** La versi√≥n open source de `MLflow` no provee ning√∫n tipo de autenticaci√≥n\n",
    "* **Versionamiento de datos** \n",
    "    * Para asegurar total reproducibilidad, necesitamos versionar los datos que se usan para entrenar el modelo.\n",
    "    * `MLflow` no provee una soluci√≥n para eso, pero hay maneras de mitigarlo\n",
    "* **Monitoreo del modelo y datos:** Veremos la herramienta adecuada para este fin "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Databricks  \n",
    "<div style=\"text-align:center\">\n",
    "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/6/63/Databricks_Logo.png\" alt=\"Databricks Logo\" width=\"300\">\n",
    "</div>\n",
    "\n",
    "### üí° Introducci√≥n  \n",
    "**Databricks** es mucho m√°s que una plataforma: es el punto de encuentro entre los datos, la anal√≠tica y el aprendizaje autom√°tico.  \n",
    "Naci√≥ de los creadores de **Apache Spark**, y hoy impulsa el trabajo colaborativo entre ingenieros, cient√≠ficos de datos y analistas dentro de un mismo entorno unificado.  \n",
    "\n",
    "Su mayor fortaleza est√° en la **integraci√≥n nativa con MLflow**, el framework open source creado tambi√©n por Databricks para gestionar el ciclo de vida completo de los modelos de *machine learning*: desde el tracking de experimentos hasta el registro, versionado y despliegue.  \n",
    "\n",
    "En pocas palabras, Databricks ofrece el espacio perfecto para llevar las ideas desde el *notebook* hasta producci√≥n, con escalabilidad, control y colaboraci√≥n en la nube ‚Äî todo sin fricci√≥n. ‚ö°  \n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Caracter√≠sticas Clave  \n",
    "1. **Plataforma Unificada**: Combina an√°lisis de datos, machine learning e ingenier√≠a en un mismo espacio colaborativo.  \n",
    "2. **Escalabilidad Transparente**: Ejecuta cargas en la nube sin preocuparte por la infraestructura subyacente.  \n",
    "3. **Integraci√≥n con MLflow**: Registra, compara y despliega modelos directamente desde la interfaz de Databricks.  \n",
    "4. **Workspaces Colaborativos**: Crea notebooks compartidos, comenta resultados y trabaja en tiempo real con tu equipo.  \n",
    "5. **Arquitectura Lakehouse**: Integra data lakes y data warehouses en una √∫nica fuente de verdad.  \n",
    "6. **Automatizaci√≥n de Pipelines**: Orquesta jobs y flujos de ML con solo unos clics o scripts reproducibles.  \n",
    "7. **Conectividad Total**: Compatible con GitHub, APIs y herramientas open source del ecosistema ML.\n",
    "\n",
    "---\n",
    "\n",
    "### Pasos para Crear una Cuenta Gratuita en Databricks Free Edition\n",
    "1. Dir√≠gete a la p√°gina oficial de registro de cuenta gratuita: [Registrarse en Free Edition](https://www.databricks.com/learn/free-edition)  \n",
    "2. Haz clic en **\"Sign up for Free Edition\"** y registra un correo electr√≥nico.\n",
    "3. Completa el formulario con los datos solicitados.  \n",
    "4. Acepta los t√©rminos de servicio y haz clic en crear la cuenta.  \n",
    "5. Autom√°ticamente se crear√° un **workspace** gratuito para ti, sin necesidad de elegir proveedor de nube. \n",
    "\n",
    "---\n",
    "\n",
    "#### Nota:\n",
    "- Esta edici√≥n gratuita (‚ÄúFree Edition‚Äù) es ideal para aprendizaje, pruebas, prototipos, pero **tiene limitaciones** de recursos, como uso reducido de c√≥mputo y almacenamiento.\n",
    "- No necesitas elegir un proveedor de nube durante el registro de la Free Edition; la plataforma gestiona autom√°ticamente el entorno.  \n",
    "- La integraci√≥n de MLflow ya viene incluida dentro del ecosistema Databricks ‚Äî no es necesario configurarla aparte.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß≠ Actividad: Experimentos de MLflow en Databricks\n",
    "\n",
    "**Objetivo:** aprender a **rastrear experimentos** y **registrar modelos** con **MLflow** usando **Databricks** en el repositorio `nyc-taxi-prediction-2025`.\n",
    "\n",
    "---\n",
    "\n",
    "### 1) Preparaci√≥n del repositorio (git)\n",
    "\n",
    "1. Aseg√∫rate de estar al d√≠a en la rama `main`:\n",
    "   ```bash\n",
    "   git checkout main && git pull origin main\n",
    "   ```\n",
    "2. Crea la nueva rama de trabajo:\n",
    "   ```bash\n",
    "   git checkout -b databricks-experiments\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### 2) Crear estructura para los experimentos\n",
    "\n",
    "1. En la **ra√≠z** del repo, crea el directorio:\n",
    "   ```bash\n",
    "   mkdir -p experiments\n",
    "   ```\n",
    "2. Crea el notebook vac√≠o:\n",
    "   ```\n",
    "   experiments/01-databricks_mlflow_model_experiments.ipynb\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### 3) Crear el archivo `.env` con credenciales de Databricks\n",
    "\n",
    "1. Inicia sesi√≥n en **Databricks Free Edition**.  \n",
    "2. Copia la URL de tu workspace (servir√° como `DATABRICKS_HOST`), con forma:\n",
    "   ```\n",
    "   https://<tu-workspace>.cloud.databricks.com\n",
    "   ```\n",
    "3. Genera un **Personal Access Token (PAT)**:\n",
    "   - Ve a *User settings ‚Üí Developer ‚Üí Access tokens ‚Üí Generate new token*.\n",
    "   - Copia el token (solo se muestra una vez).\n",
    "\n",
    "4. En la **ra√≠z** del repositorio, crea un archivo `.env` con el siguiente contenido:\n",
    "\n",
    "   ```\n",
    "   DATABRICKS_HOST=https://<tu-workspace>.cloud.databricks.com\n",
    "   DATABRICKS_TOKEN=<TU_TOKEN>\n",
    "   ```\n",
    "\n",
    "5. Aseg√∫rate de agregar `.env` al archivo `.gitignore` para **no subirlo al repositorio**.\n",
    "\n",
    "üß© **Datos que necesitaremos:**\n",
    "- `DATABRICKS_HOST` ‚Üí URL de tu workspace.  \n",
    "- `DATABRICKS_TOKEN` ‚Üí tu token personal.  \n",
    "\n",
    "---\n",
    "\n",
    "### 4) Instalar dependencias necesarias\n",
    "\n",
    "Con **uv**:\n",
    "```bash\n",
    "uv add mlflow jupyter xgboost optuna\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Configurar el *Experiment* en el notebook\n",
    "\n",
    "Primera celda del archivo `experiments/01-databricks_mlflow_model_experiments.ipynb`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, mlflow\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)  # Carga las variables del archivo .env\n",
    "EXPERIMENT_NAME = \"/Users/<tu_correo>/nyc-taxi-experiments\"\n",
    "\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "experiment = mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLFlow Cheatsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ml flow cheatsheet](images/mlflow-cheatsheet.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos a reutilizar el c√≥digo que ya hemos usado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar las librer√≠as necesarias y definir funci√≥n para importar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import  root_mean_squared_error\n",
    "from sklearn.feature_extraction import  DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe('../data/green_tripdata_2025-01.parquet')\n",
    "df_val = read_dataframe('../data/green_tripdata_2025-02.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering + One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, dv):\n",
    "    df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
    "    categorical = ['PU_DO']\n",
    "    numerical = ['trip_distance']\n",
    "    train_dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    return dv.transform(train_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "X_val = preprocess(df_val, dv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir los `dataset` como objetos de `mlflow` para poderlos trackear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = mlflow.data.from_numpy(X_train.data, targets=y_train, name=\"green_tripdata_2025-01\")\n",
    "validation_dataset = mlflow.data.from_numpy(X_val.data, targets=y_val, name=\"green_tripdata_2025-02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Tunning de Hiper-par√°metros para un modelo `xgboost` - Optuna\n",
    "\n",
    "El **tunning de hiper-par√°metros** consiste en encontrar la mejor combinaci√≥n de par√°metros que optimizan el rendimiento de un modelo.\n",
    "\n",
    "En lugar de probar valores manualmente, usamos librer√≠as como **Optuna**, que aplican estrategias inteligentes de b√∫squeda (*Bayesian optimization*, *Tree-structured Parzen Estimator*, etc.) para acelerar el proceso y encontrar resultados m√°s robustos.\n",
    "\n",
    "En este caso, usaremos **Optuna** para ajustar un modelo de **XGBoost**, definiendo un espacio de b√∫squeda para par√°metros como:\n",
    "| Par√°metro | Descripci√≥n |\n",
    "|------------|--------------|\n",
    "| `max_depth` | Profundidad m√°xima de los √°rboles | \n",
    "| `learning_rate` | Tasa de aprendizaje (escala logar√≠tmica) | \n",
    "| `reg_alpha` | Regularizaci√≥n L1 (Œ±) | \n",
    "| `reg_lambda` | Regularizaci√≥n L2 (Œª) | \n",
    "| `min_child_weight` | Peso m√≠nimo de muestras por hoja | \n",
    "| `objective` | Funci√≥n objetivo | \n",
    "| `seed` | Semilla aleatoria | \n",
    "\n",
    "Durante el proceso, Optuna crea un **‚Äústudy‚Äù** donde cada *trial* representa una combinaci√≥n de par√°metros probada.  \n",
    "\n",
    "Cada *trial* puede registrarse con **MLflow**, lo que permite visualizar m√©tricas, comparar resultados y seleccionar el modelo m√°s prometedor.\n",
    "\n",
    "Ejemplo simplificado de estructura:\n",
    "\n",
    "```python\n",
    "import math, optuna, xgboost as xgb, mlflow\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 100),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", math.exp(-3), 1.0, log=True),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", math.exp(-5), math.exp(-1), log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", math.exp(-6), math.exp(-1), log=True),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", math.exp(-1), math.exp(3), log=True),\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"seed\": 42,\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.log_params(params)\n",
    "        booster = xgb.train(params, dtrain, evals=[(dvalid, \"validation\")])\n",
    "        preds = booster.predict(dvalid)\n",
    "        rmse = mean_squared_error(y_valid, preds, squared=False)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "    return rmse\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "```\n",
    "\n",
    "üîπ **Ventajas de usar Optuna con MLflow:**\n",
    "- Seguimiento autom√°tico de m√©tricas y par√°metros.  \n",
    "- Comparaci√≥n visual de resultados en la UI de MLflow.  \n",
    "- Integraci√≥n fluida con Databricks y notebooks colaborativos.  \n",
    "\n",
    "---\n",
    "\n",
    "üìö **Referencia interesante:**  \n",
    "üëâ [https://xgboosting.com/](https://xgboosting.com/) ‚Äî Gu√≠a pr√°ctica con ejemplos avanzados de *tunning* y t√©cnicas modernas para modelos de **XGBoost** y **Optuna**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import optuna\n",
    "import pathlib\n",
    "import xgboost as xgb\n",
    "from optuna.samplers import TPESampler\n",
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funci√≥n Objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Definir la funci√≥n objetivo para Optuna\n",
    "#    - Recibe un `trial`, que se usa para proponer hiperpar√°metros.\n",
    "#    - Entrena un modelo con esos hiperpar√°metros.\n",
    "#    - Calcula la m√©trica de validaci√≥n (RMSE) y la retorna (Optuna la minimizar√°).\n",
    "#    - Abrimos un run anidado de MLflow para registrar cada trial.\n",
    "# ------------------------------------------------------------\n",
    "def objective(trial: optuna.trial.Trial):\n",
    "    # Hiperpar√°metros MUESTREADOS por Optuna en CADA trial.\n",
    "    # Nota: usamos log=True para emular rangos log-uniformes (similar a loguniform).\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 100),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", math.exp(-3), 1.0, log=True),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\",   math.exp(-5), math.exp(-1), log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", math.exp(-6), math.exp(-1), log=True),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", math.exp(-1), math.exp(3), log=True),\n",
    "        \"objective\": \"reg:squarederror\",  \n",
    "        \"seed\": 42,                      \n",
    "    }\n",
    "\n",
    "    # Run anidado para dejar rastro de cada trial en MLflow\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.set_tag(\"model_family\", \"xgboost\")  # etiqueta informativa\n",
    "        mlflow.log_params(params)                  # registra hiperpar√°metros del trial\n",
    "\n",
    "        # Entrenamiento con early stopping en el conjunto de validaci√≥n\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=100,\n",
    "            evals=[(valid, \"validation\")],\n",
    "            early_stopping_rounds=10,\n",
    "        )\n",
    "\n",
    "        # Predicci√≥n y m√©trica en validaci√≥n\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "        # Registrar la m√©trica principal\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        # La \"signature\" describe la estructura esperada de entrada y salida del modelo:\n",
    "        # incluye los nombres, tipos y forma (shape) de las variables de entrada y el tipo de salida.\n",
    "        # MLflow la usa para validar datos en inferencia y documentar el modelo en el Model Registry.\n",
    "        signature = infer_signature(X_val, y_pred)\n",
    "\n",
    "        # Guardar el modelo del trial como artefacto en MLflow.\n",
    "        mlflow.xgboost.log_model(\n",
    "            booster,\n",
    "            name=\"model\",\n",
    "            input_example=X_val[:5],\n",
    "            signature=signature\n",
    "        )\n",
    "\n",
    "    # Optuna minimiza el valor retornado\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flujo de b√∫squeda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.xgboost.autolog(log_models=False)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Crear el estudio de Optuna\n",
    "#    - Usamos TPE (Tree-structured Parzen Estimator) como sampler.\n",
    "#    - direction=\"minimize\" porque queremos minimizar el RMSE.\n",
    "# ------------------------------------------------------------\n",
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Ejecutar la optimizaci√≥n (n_trials = n√∫mero de intentos)\n",
    "#    - Cada trial ejecuta la funci√≥n objetivo con un set distinto de hiperpar√°metros.\n",
    "#    - Abrimos un run \"padre\" para agrupar toda la b√∫squeda.\n",
    "# ------------------------------------------------------------\n",
    "with mlflow.start_run(run_name=\"XGBoost Hyperparameter Optimization (Optuna)\", nested=True):\n",
    "    study.optimize(objective, n_trials=3)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Recuperar y registrar los mejores hiperpar√°metros\n",
    "    # --------------------------------------------------------\n",
    "    best_params = study.best_params\n",
    "    # Asegurar tipos/campos fijos (por claridad y consistencia)\n",
    "    best_params[\"max_depth\"] = int(best_params[\"max_depth\"])\n",
    "    best_params[\"seed\"] = 42\n",
    "    best_params[\"objective\"] = \"reg:squarederror\"\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # Etiquetas del run \"padre\" (metadatos del experimento)\n",
    "    mlflow.set_tags({\n",
    "        \"project\": \"NYC Taxi Time Prediction Project\",\n",
    "        \"optimizer_engine\": \"optuna\",\n",
    "        \"model_family\": \"xgboost\",\n",
    "        \"feature_set_version\": 1,\n",
    "    })\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 7) Entrenar un modelo FINAL con los mejores hiperpar√°metros\n",
    "    #    (normalmente se har√≠a sobre train+val o con CV; aqu√≠ mantenemos el patr√≥n original)\n",
    "    # --------------------------------------------------------\n",
    "    booster = xgb.train(\n",
    "        params=best_params,\n",
    "        dtrain=train,\n",
    "        num_boost_round=100,\n",
    "        evals=[(valid, \"validation\")],\n",
    "        early_stopping_rounds=10,\n",
    "    )\n",
    "\n",
    "    # Evaluar y registrar la m√©trica final en validaci√≥n\n",
    "    y_pred = booster.predict(valid)\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 8) Guardar artefactos adicionales (p. ej. el preprocesador)\n",
    "    # --------------------------------------------------------\n",
    "    pathlib.Path(\"preprocessor\").mkdir(exist_ok=True)\n",
    "    with open(\"preprocessor/preprocessor.b\", \"wb\") as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "\n",
    "    mlflow.log_artifact(\"preprocessor/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "\n",
    "    # La \"signature\" describe la estructura esperada de entrada y salida del modelo:\n",
    "    # incluye los nombres, tipos y forma (shape) de las variables de entrada y el tipo de salida.\n",
    "    # MLflow la usa para validar datos en inferencia y documentar el modelo en el Model Registry.\n",
    "    # Si X_val es la matriz dispersa (scipy.sparse) salida de DictVectorizer:\n",
    "    feature_names = dv.get_feature_names_out()\n",
    "    input_example = pd.DataFrame(X_val[:5].toarray(), columns=feature_names)\n",
    "\n",
    "    # Para que las longitudes coincidan, usa el mismo slice en y_pred\n",
    "    signature = infer_signature(input_example, y_val[:5])\n",
    "\n",
    "    # Guardar el modelo del trial como artefacto en MLflow.\n",
    "    mlflow.xgboost.log_model(\n",
    "        booster,\n",
    "        name=\"model\",\n",
    "        input_example=input_example,\n",
    "        signature=signature\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registrar modelo en `Model Registry`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"workspace.default.nyc-taxi-model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = input(\"Ingrese el run_id\")\n",
    "run_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "result = mlflow.register_model(\n",
    "    model_uri=run_uri,\n",
    "    name=\"workspace.default.nyc-taxi-model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs(\n",
    "    experiment_names=[EXPERIMENT_NAME],\n",
    "    order_by=[\"metrics.rmse ASC\"],\n",
    "    output_format=\"list\"\n",
    ")\n",
    "\n",
    "# Obtener el mejor run\n",
    "if len(runs) > 0:\n",
    "    best_run = runs[0]\n",
    "    print(\"üèÜ Champion Run encontrado:\")\n",
    "    print(f\"Run ID: {best_run.info.run_id}\")\n",
    "    print(f\"RMSE: {best_run.data.metrics['rmse']}\")\n",
    "    print(f\"Params: {best_run.data.params}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se encontraron runs con m√©trica RMSE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = mlflow.register_model(\n",
    "    model_uri=f\"runs:/{best_run.info.run_id}/model\",\n",
    "    name=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asignar alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = result.version\n",
    "new_alias = \"Champion\"\n",
    "\n",
    "client.set_registered_model_alias(\n",
    "    name=model_name,\n",
    "    alias=new_alias,\n",
    "    version=result.version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "date = datetime.today()\n",
    "\n",
    "client.update_model_version(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    description=f\"The model version {model_version} was transitioned to {new_alias} on {date}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obteniendo modelos del `Moldel Registry`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "model_version_uri = f\"models:/{model_name}@Champion\"\n",
    "\n",
    "champion_version = mlflow.pyfunc.load_model(model_version_uri)\n",
    "champion_version.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Tarea y actividad en clase.\n",
    "\n",
    "1. Hacer merge de la rama que trabajamos a main.\n",
    "2. Crear una nueva rama que se llame `feat: tarea 5`.\n",
    "3. Crear un nuevo `jupyter-notebook` llamado `challenger-experiments.ipynb` en la rama creada anteriormente\n",
    "4. Hacer dos `parent experiments` con `Gradient Boost` y `Random Forest` regressors en donde cada uno tenga `child experiments` con b√∫squeda de hyper-par√°metros. Puede usar cualquier librerar√≠a con la que se sienta c√≥modo: `hyperopt`, `optuna`, `scikit-learn` (Grid Search, Random Search, Halving Search etc)\n",
    "5. Registrar el modelo con la mejor m√©trica `validation-rmse` de los obtenidos en dichos experimentos en el `model registry` en el mismo modelo ya previamente creado `nyc-taxi-model`.\n",
    "6. As√≠gnele el alias `challenger`\n",
    "7. Descargue en la carpeta `data` el conjunto de datos correspondiente a marzo del 2025\n",
    "9. Use ese conjunto de datos para probarlo sobre los modelos con el alias `champion` y `challenger`\n",
    "10. Obtenga la m√©trica de cada modelo\n",
    "11. Decida si el nuevo modelo `challenger` debe ser promovido a `champion` o no. Use los criterios que usted como Data Scientis considere relevantes y justifique la respuesta.\n",
    "12. Abrir un `PR` con los cambios hechos en la rama `feat: tarea 5` hacia la rama `main`.\n",
    "\n",
    "\n",
    "Habr√° dos entregas divididas de la siguiente manera:\n",
    "\n",
    "1. **Trabajo en clase hoy Martes 21 de Octubre de 2025.** Para esta entrega, hacer un commit con el siguiente mensaje `feat: entrega trabajo en clase` con los avances realizados en clase.\n",
    "\n",
    "2. **Tarea: Martes 28 de Octubre de 2025 a las 19:55.** Esta entrega debe contener todo lo descrito anteriormente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Anexo: c√≥mo resolver errores de OpenMP (`libomp` / `libgomp`) con XGBoost\n",
    "\n",
    "Cuando entrenas XGBoost, a veces aparecen errores tipo **‚Äúlibrary not loaded: libomp.dylib‚Äù** (macOS) o **‚Äúcannot open shared object file: libgomp.so.1‚Äù** (Linux) o problemas con **vcomp / OpenMP** (Windows). Aqu√≠ tienes soluciones por sistema operativo.\n",
    "\n",
    "---\n",
    "\n",
    "### üçè macOS (Intel y Apple Silicon)\n",
    "**S√≠ntoma com√∫n:**  \n",
    "`OSError: dlopen(... libxgboost.dylib ...): Library not loaded: @rpath/libomp.dylib`\n",
    "\n",
    "**Soluci√≥n r√°pida con Homebrew (recomendado):**\n",
    "```bash\n",
    "# Instalar / reinstalar OpenMP\n",
    "brew update\n",
    "brew install libomp || brew reinstall libomp\n",
    "\n",
    "# (opcional) Si sigues con el error en notebooks lanzados desde terminal:\n",
    "# export DYLD_LIBRARY_PATH antes de abrir Jupyter\n",
    "echo 'export DYLD_LIBRARY_PATH=\"/opt/homebrew/opt/libomp/lib:$DYLD_LIBRARY_PATH\"' >> ~/.zshrc\n",
    "source ~/.zshrc\n",
    "```\n",
    "\n",
    "**Alternativas:**\n",
    "- Si usas **Conda**: `conda install -c conda-forge xgboost libomp`  \n",
    "  (las builds de conda-forge suelen traer las dependencias resueltas).\n",
    "- En **Jupyter**, reinicia el kernel despu√©s de instalar `libomp`.\n",
    "- Si el consumo de hilos es demasiado alto en laptops:  \n",
    "  `export OMP_NUM_THREADS=4` (ajusta a tus cores).\n",
    "\n",
    "---\n",
    "\n",
    "### ü™ü Windows (PowerShell / CMD)\n",
    "**S√≠ntomas comunes:**\n",
    "- Errores de OpenMP/vcomp o fallos al cargar `xgboost.dll`.\n",
    "- En WSL (Ubuntu) ver la secci√≥n Linux.\n",
    "\n",
    "**Soluci√≥n:**\n",
    "1. Aseg√∫rate de usar **x64** y Python de 64 bits.\n",
    "2. Instala/actualiza el **Microsoft Visual C++ Redistributable (2015‚Äì2022)**.  \n",
    "   (Busca ‚ÄúMicrosoft Visual C++ Redistributable x64‚Äù en el sitio oficial de Microsoft e inst√°lalo).\n",
    "3. Reinstala XGBoost:\n",
    "   ```powershell\n",
    "   pip install --upgrade --force-reinstall xgboost\n",
    "   ```\n",
    "4. Si tu CPU es de pocos n√∫cleos o ves uso excesivo:\n",
    "   ```powershell\n",
    "   setx OMP_NUM_THREADS 4\n",
    "   ```\n",
    "   (Cierra y abre la terminal para que aplique).\n",
    "\n",
    "**Notas:**\n",
    "- Si usas **Conda**: `conda install -c conda-forge xgboost` suele resolver las DLLs.\n",
    "- En entornos corporativos restringidos, ejecuta terminal como **Administrador** para el redistributable.\n",
    "\n",
    "---\n",
    "\n",
    "### üêß Linux (Ubuntu/Debian, Fedora, Alpine, Docker)\n",
    "**S√≠ntoma com√∫n:**  \n",
    "`ImportError: libgomp.so.1: cannot open shared object file: No such file or directory`\n",
    "\n",
    "**Soluci√≥n (Ubuntu/Debian):**\n",
    "```bash\n",
    "sudo apt-get update\n",
    "sudo apt-get install -y libgomp1\n",
    "```\n",
    "\n",
    "**Fedora/CentOS/RHEL:**\n",
    "```bash\n",
    "sudo dnf install -y libgomp   # o\n",
    "sudo yum install -y libgomp\n",
    "```\n",
    "\n",
    "**Alpine (musl):**\n",
    "```bash\n",
    "sudo apk add libgomp\n",
    "```\n",
    "\n",
    "**Docker (por ejemplo, python:3.11-slim):**\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends libgomp1 && rm -rf /var/lib/apt/lists/*\n",
    "RUN pip install xgboost\n",
    "```\n",
    "\n",
    "**WSL (Ubuntu):**  \n",
    "Sigue los pasos de Ubuntu/Debian y reinicia el kernel/notebook.\n",
    "\n",
    "**Control de hilos (opcional):**\n",
    "```bash\n",
    "export OMP_NUM_THREADS=4\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
